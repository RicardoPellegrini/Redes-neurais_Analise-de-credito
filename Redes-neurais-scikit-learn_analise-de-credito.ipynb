{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando database\n",
    "base = pd.read_csv('credit_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i#clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>c#default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>45331.600018</td>\n",
       "      <td>40.807559</td>\n",
       "      <td>4444.369695</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>577.494589</td>\n",
       "      <td>14326.327119</td>\n",
       "      <td>13.624469</td>\n",
       "      <td>3045.410024</td>\n",
       "      <td>0.348624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20014.489470</td>\n",
       "      <td>-52.423280</td>\n",
       "      <td>1.377630</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.750000</td>\n",
       "      <td>32796.459717</td>\n",
       "      <td>28.990415</td>\n",
       "      <td>1939.708847</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1000.500000</td>\n",
       "      <td>45789.117313</td>\n",
       "      <td>41.317159</td>\n",
       "      <td>3974.719419</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1500.250000</td>\n",
       "      <td>57791.281668</td>\n",
       "      <td>52.587040</td>\n",
       "      <td>6432.410625</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>69995.685578</td>\n",
       "      <td>63.971796</td>\n",
       "      <td>13766.051239</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        i#clientid        income          age          loan    c#default\n",
       "count  2000.000000   2000.000000  1997.000000   2000.000000  2000.000000\n",
       "mean   1000.500000  45331.600018    40.807559   4444.369695     0.141500\n",
       "std     577.494589  14326.327119    13.624469   3045.410024     0.348624\n",
       "min       1.000000  20014.489470   -52.423280      1.377630     0.000000\n",
       "25%     500.750000  32796.459717    28.990415   1939.708847     0.000000\n",
       "50%    1000.500000  45789.117313    41.317159   3974.719419     0.000000\n",
       "75%    1500.250000  57791.281668    52.587040   6432.410625     0.000000\n",
       "max    2000.000000  69995.685578    63.971796  13766.051239     1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estatísticas do database\n",
    "base.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i#clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>c#default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>66155.925095</td>\n",
       "      <td>59.017015</td>\n",
       "      <td>8106.532131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34415.153966</td>\n",
       "      <td>48.117153</td>\n",
       "      <td>6564.745018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>57317.170063</td>\n",
       "      <td>63.108049</td>\n",
       "      <td>8020.953296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42709.534201</td>\n",
       "      <td>45.751972</td>\n",
       "      <td>6103.642260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>66952.688845</td>\n",
       "      <td>18.584336</td>\n",
       "      <td>8770.099235</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i#clientid        income        age         loan  c#default\n",
       "0           1  66155.925095  59.017015  8106.532131          0\n",
       "1           2  34415.153966  48.117153  6564.745018          0\n",
       "2           3  57317.170063  63.108049  8020.953296          0\n",
       "3           4  42709.534201  45.751972  6103.642260          0\n",
       "4           5  66952.688845  18.584336  8770.099235          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Amostra dos dados\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i#clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>c#default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>50501.726689</td>\n",
       "      <td>-28.218361</td>\n",
       "      <td>3977.287432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>32197.620701</td>\n",
       "      <td>-52.423280</td>\n",
       "      <td>4244.057136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>63287.038908</td>\n",
       "      <td>-36.496976</td>\n",
       "      <td>9595.286289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i#clientid        income        age         loan  c#default\n",
       "15          16  50501.726689 -28.218361  3977.287432          0\n",
       "21          22  32197.620701 -52.423280  4244.057136          0\n",
       "26          27  63287.038908 -36.496976  9595.286289          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando dados com idade negativa\n",
    "base.loc[base['age'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Maneiras de contornar o problema das idades menores que zero\n",
    "\n",
    "## 1) Apagar a coluna por inteiro (não recomendada, neste caso)\n",
    "# base.drop('age', 1, inplace=True)\n",
    "\n",
    "## 2) Apagar apenas os registros, por completo, que possuem essa incoerência\n",
    "# base.drop(base[base.age < 0].index, inplace=True)\n",
    "\n",
    "## 3) Preencher os valores com a média da coluna, apenas dos valores maiores que zero\n",
    "media = base['age'][base.age > 0].mean()\n",
    "base.loc[base.age < 0, 'age'] = media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i#clientid</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>loan</th>\n",
       "      <th>c#default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>59417.805406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2082.625938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>48528.852796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6155.784670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>23526.302555</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2862.010139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i#clientid        income  age         loan  c#default\n",
       "28          29  59417.805406  NaN  2082.625938          0\n",
       "30          31  48528.852796  NaN  6155.784670          0\n",
       "31          32  23526.302555  NaN  2862.010139          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando valores nulos\n",
    "base.loc[pd.isnull(base['age'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão do dataset entre variáveis preditoras e target\n",
    "previsores = base.iloc[:, 1:4].values\n",
    "classe = base.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo os valores missing pela média de cada coluna\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imputer.fit(previsores[:, 0:3])\n",
    "\n",
    "previsores[:, 0:3] = imputer.transform(previsores[:, 0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fazendo o escalonamento (normalização) dos atributos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Padronização\n",
    "scaler = StandardScaler()\n",
    "previsores = scaler.fit_transform(previsores)\n",
    "\n",
    "# Normalização\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# previsores = scaler.fit_transform(previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em treino e teste\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_train, previsores_test, classe_train, classe_test = train_test_split(previsores, classe, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Redes Neurais\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = MLPClassifier(\n",
    "    verbose=True,\n",
    "    max_iter=500,\n",
    "    tol=0.00001,\n",
    "    solver='adam',\n",
    "    hidden_layer_sizes=(100),\n",
    "    activation='relu',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.72719090\n",
      "Iteration 2, loss = 0.65396861\n",
      "Iteration 3, loss = 0.59078723\n",
      "Iteration 4, loss = 0.53645600\n",
      "Iteration 5, loss = 0.49037435\n",
      "Iteration 6, loss = 0.45015770\n",
      "Iteration 7, loss = 0.41523607\n",
      "Iteration 8, loss = 0.38456154\n",
      "Iteration 9, loss = 0.35728487\n",
      "Iteration 10, loss = 0.33327620\n",
      "Iteration 11, loss = 0.31144185\n",
      "Iteration 12, loss = 0.29199821\n",
      "Iteration 13, loss = 0.27458335\n",
      "Iteration 14, loss = 0.25900377\n",
      "Iteration 15, loss = 0.24493808\n",
      "Iteration 16, loss = 0.23237911\n",
      "Iteration 17, loss = 0.22116095\n",
      "Iteration 18, loss = 0.21098915\n",
      "Iteration 19, loss = 0.20172527\n",
      "Iteration 20, loss = 0.19338834\n",
      "Iteration 21, loss = 0.18588585\n",
      "Iteration 22, loss = 0.17889662\n",
      "Iteration 23, loss = 0.17259952\n",
      "Iteration 24, loss = 0.16677579\n",
      "Iteration 25, loss = 0.16142745\n",
      "Iteration 26, loss = 0.15654611\n",
      "Iteration 27, loss = 0.15205232\n",
      "Iteration 28, loss = 0.14778792\n",
      "Iteration 29, loss = 0.14397278\n",
      "Iteration 30, loss = 0.14034830\n",
      "Iteration 31, loss = 0.13696992\n",
      "Iteration 32, loss = 0.13384240\n",
      "Iteration 33, loss = 0.13088562\n",
      "Iteration 34, loss = 0.12812667\n",
      "Iteration 35, loss = 0.12554588\n",
      "Iteration 36, loss = 0.12293561\n",
      "Iteration 37, loss = 0.12070698\n",
      "Iteration 38, loss = 0.11848323\n",
      "Iteration 39, loss = 0.11632691\n",
      "Iteration 40, loss = 0.11428267\n",
      "Iteration 41, loss = 0.11241606\n",
      "Iteration 42, loss = 0.11064705\n",
      "Iteration 43, loss = 0.10886570\n",
      "Iteration 44, loss = 0.10718344\n",
      "Iteration 45, loss = 0.10561040\n",
      "Iteration 46, loss = 0.10410228\n",
      "Iteration 47, loss = 0.10259410\n",
      "Iteration 48, loss = 0.10118424\n",
      "Iteration 49, loss = 0.09984250\n",
      "Iteration 50, loss = 0.09845442\n",
      "Iteration 51, loss = 0.09718918\n",
      "Iteration 52, loss = 0.09602784\n",
      "Iteration 53, loss = 0.09479522\n",
      "Iteration 54, loss = 0.09356449\n",
      "Iteration 55, loss = 0.09247797\n",
      "Iteration 56, loss = 0.09136647\n",
      "Iteration 57, loss = 0.09032140\n",
      "Iteration 58, loss = 0.08927169\n",
      "Iteration 59, loss = 0.08823189\n",
      "Iteration 60, loss = 0.08726162\n",
      "Iteration 61, loss = 0.08629178\n",
      "Iteration 62, loss = 0.08529499\n",
      "Iteration 63, loss = 0.08432325\n",
      "Iteration 64, loss = 0.08340278\n",
      "Iteration 65, loss = 0.08245557\n",
      "Iteration 66, loss = 0.08157578\n",
      "Iteration 67, loss = 0.08066417\n",
      "Iteration 68, loss = 0.07974852\n",
      "Iteration 69, loss = 0.07881098\n",
      "Iteration 70, loss = 0.07789499\n",
      "Iteration 71, loss = 0.07704202\n",
      "Iteration 72, loss = 0.07620536\n",
      "Iteration 73, loss = 0.07539954\n",
      "Iteration 74, loss = 0.07460246\n",
      "Iteration 75, loss = 0.07381565\n",
      "Iteration 76, loss = 0.07303797\n",
      "Iteration 77, loss = 0.07227295\n",
      "Iteration 78, loss = 0.07153270\n",
      "Iteration 79, loss = 0.07083397\n",
      "Iteration 80, loss = 0.07025567\n",
      "Iteration 81, loss = 0.06936895\n",
      "Iteration 82, loss = 0.06870250\n",
      "Iteration 83, loss = 0.06793946\n",
      "Iteration 84, loss = 0.06732695\n",
      "Iteration 85, loss = 0.06666898\n",
      "Iteration 86, loss = 0.06600457\n",
      "Iteration 87, loss = 0.06536393\n",
      "Iteration 88, loss = 0.06470719\n",
      "Iteration 89, loss = 0.06410261\n",
      "Iteration 90, loss = 0.06357736\n",
      "Iteration 91, loss = 0.06290276\n",
      "Iteration 92, loss = 0.06235130\n",
      "Iteration 93, loss = 0.06176697\n",
      "Iteration 94, loss = 0.06113705\n",
      "Iteration 95, loss = 0.06055968\n",
      "Iteration 96, loss = 0.06004994\n",
      "Iteration 97, loss = 0.05946473\n",
      "Iteration 98, loss = 0.05889511\n",
      "Iteration 99, loss = 0.05841847\n",
      "Iteration 100, loss = 0.05782769\n",
      "Iteration 101, loss = 0.05729845\n",
      "Iteration 102, loss = 0.05686107\n",
      "Iteration 103, loss = 0.05629296\n",
      "Iteration 104, loss = 0.05583689\n",
      "Iteration 105, loss = 0.05536458\n",
      "Iteration 106, loss = 0.05511256\n",
      "Iteration 107, loss = 0.05434526\n",
      "Iteration 108, loss = 0.05385337\n",
      "Iteration 109, loss = 0.05336049\n",
      "Iteration 110, loss = 0.05298940\n",
      "Iteration 111, loss = 0.05253675\n",
      "Iteration 112, loss = 0.05214438\n",
      "Iteration 113, loss = 0.05160689\n",
      "Iteration 114, loss = 0.05116051\n",
      "Iteration 115, loss = 0.05073209\n",
      "Iteration 116, loss = 0.05028422\n",
      "Iteration 117, loss = 0.04992739\n",
      "Iteration 118, loss = 0.04948253\n",
      "Iteration 119, loss = 0.04910490\n",
      "Iteration 120, loss = 0.04872160\n",
      "Iteration 121, loss = 0.04834520\n",
      "Iteration 122, loss = 0.04794055\n",
      "Iteration 123, loss = 0.04757047\n",
      "Iteration 124, loss = 0.04730914\n",
      "Iteration 125, loss = 0.04704213\n",
      "Iteration 126, loss = 0.04655186\n",
      "Iteration 127, loss = 0.04623300\n",
      "Iteration 128, loss = 0.04592490\n",
      "Iteration 129, loss = 0.04546267\n",
      "Iteration 130, loss = 0.04510653\n",
      "Iteration 131, loss = 0.04488218\n",
      "Iteration 132, loss = 0.04443321\n",
      "Iteration 133, loss = 0.04411672\n",
      "Iteration 134, loss = 0.04380920\n",
      "Iteration 135, loss = 0.04346072\n",
      "Iteration 136, loss = 0.04316081\n",
      "Iteration 137, loss = 0.04288854\n",
      "Iteration 138, loss = 0.04254326\n",
      "Iteration 139, loss = 0.04230280\n",
      "Iteration 140, loss = 0.04201462\n",
      "Iteration 141, loss = 0.04170617\n",
      "Iteration 142, loss = 0.04140572\n",
      "Iteration 143, loss = 0.04113738\n",
      "Iteration 144, loss = 0.04087962\n",
      "Iteration 145, loss = 0.04057576\n",
      "Iteration 146, loss = 0.04041546\n",
      "Iteration 147, loss = 0.04005991\n",
      "Iteration 148, loss = 0.03974377\n",
      "Iteration 149, loss = 0.03957398\n",
      "Iteration 150, loss = 0.03944178\n",
      "Iteration 151, loss = 0.03902222\n",
      "Iteration 152, loss = 0.03877159\n",
      "Iteration 153, loss = 0.03851531\n",
      "Iteration 154, loss = 0.03826396\n",
      "Iteration 155, loss = 0.03806834\n",
      "Iteration 156, loss = 0.03780752\n",
      "Iteration 157, loss = 0.03752781\n",
      "Iteration 158, loss = 0.03730515\n",
      "Iteration 159, loss = 0.03715681\n",
      "Iteration 160, loss = 0.03691731\n",
      "Iteration 161, loss = 0.03664740\n",
      "Iteration 162, loss = 0.03645801\n",
      "Iteration 163, loss = 0.03621907\n",
      "Iteration 164, loss = 0.03600471\n",
      "Iteration 165, loss = 0.03576909\n",
      "Iteration 166, loss = 0.03558928\n",
      "Iteration 167, loss = 0.03540738\n",
      "Iteration 168, loss = 0.03510649\n",
      "Iteration 169, loss = 0.03503997\n",
      "Iteration 170, loss = 0.03478009\n",
      "Iteration 171, loss = 0.03457427\n",
      "Iteration 172, loss = 0.03438739\n",
      "Iteration 173, loss = 0.03415400\n",
      "Iteration 174, loss = 0.03399177\n",
      "Iteration 175, loss = 0.03393289\n",
      "Iteration 176, loss = 0.03363278\n",
      "Iteration 177, loss = 0.03344646\n",
      "Iteration 178, loss = 0.03323829\n",
      "Iteration 179, loss = 0.03312417\n",
      "Iteration 180, loss = 0.03288653\n",
      "Iteration 181, loss = 0.03276452\n",
      "Iteration 182, loss = 0.03258236\n",
      "Iteration 183, loss = 0.03234205\n",
      "Iteration 184, loss = 0.03215912\n",
      "Iteration 185, loss = 0.03199994\n",
      "Iteration 186, loss = 0.03183924\n",
      "Iteration 187, loss = 0.03167698\n",
      "Iteration 188, loss = 0.03148536\n",
      "Iteration 189, loss = 0.03130906\n",
      "Iteration 190, loss = 0.03119263\n",
      "Iteration 191, loss = 0.03101300\n",
      "Iteration 192, loss = 0.03083260\n",
      "Iteration 193, loss = 0.03078315\n",
      "Iteration 194, loss = 0.03057214\n",
      "Iteration 195, loss = 0.03057701\n",
      "Iteration 196, loss = 0.03022409\n",
      "Iteration 197, loss = 0.03007805\n",
      "Iteration 198, loss = 0.02994548\n",
      "Iteration 199, loss = 0.02984507\n",
      "Iteration 200, loss = 0.02957685\n",
      "Iteration 201, loss = 0.02967912\n",
      "Iteration 202, loss = 0.02945702\n",
      "Iteration 203, loss = 0.02921864\n",
      "Iteration 204, loss = 0.02922531\n",
      "Iteration 205, loss = 0.02891468\n",
      "Iteration 206, loss = 0.02882012\n",
      "Iteration 207, loss = 0.02866588\n",
      "Iteration 208, loss = 0.02851400\n",
      "Iteration 209, loss = 0.02840798\n",
      "Iteration 210, loss = 0.02828499\n",
      "Iteration 211, loss = 0.02811901\n",
      "Iteration 212, loss = 0.02809315\n",
      "Iteration 213, loss = 0.02794485\n",
      "Iteration 214, loss = 0.02779466\n",
      "Iteration 215, loss = 0.02767426\n",
      "Iteration 216, loss = 0.02752475\n",
      "Iteration 217, loss = 0.02744071\n",
      "Iteration 218, loss = 0.02726984\n",
      "Iteration 219, loss = 0.02723072\n",
      "Iteration 220, loss = 0.02709288\n",
      "Iteration 221, loss = 0.02701825\n",
      "Iteration 222, loss = 0.02679962\n",
      "Iteration 223, loss = 0.02666689\n",
      "Iteration 224, loss = 0.02654746\n",
      "Iteration 225, loss = 0.02647607\n",
      "Iteration 226, loss = 0.02632873\n",
      "Iteration 227, loss = 0.02621841\n",
      "Iteration 228, loss = 0.02622740\n",
      "Iteration 229, loss = 0.02601918\n",
      "Iteration 230, loss = 0.02591535\n",
      "Iteration 231, loss = 0.02606023\n",
      "Iteration 232, loss = 0.02580072\n",
      "Iteration 233, loss = 0.02555709\n",
      "Iteration 234, loss = 0.02547262\n",
      "Iteration 235, loss = 0.02539544\n",
      "Iteration 236, loss = 0.02525103\n",
      "Iteration 237, loss = 0.02513083\n",
      "Iteration 238, loss = 0.02505482\n",
      "Iteration 239, loss = 0.02497742\n",
      "Iteration 240, loss = 0.02488547\n",
      "Iteration 241, loss = 0.02475779\n",
      "Iteration 242, loss = 0.02469604\n",
      "Iteration 243, loss = 0.02464606\n",
      "Iteration 244, loss = 0.02443382\n",
      "Iteration 245, loss = 0.02433463\n",
      "Iteration 246, loss = 0.02428161\n",
      "Iteration 247, loss = 0.02421893\n",
      "Iteration 248, loss = 0.02403541\n",
      "Iteration 249, loss = 0.02398628\n",
      "Iteration 250, loss = 0.02387790\n",
      "Iteration 251, loss = 0.02381476\n",
      "Iteration 252, loss = 0.02368218\n",
      "Iteration 253, loss = 0.02363045\n",
      "Iteration 254, loss = 0.02353790\n",
      "Iteration 255, loss = 0.02343530\n",
      "Iteration 256, loss = 0.02334121\n",
      "Iteration 257, loss = 0.02326703\n",
      "Iteration 258, loss = 0.02312983\n",
      "Iteration 259, loss = 0.02307473\n",
      "Iteration 260, loss = 0.02299737\n",
      "Iteration 261, loss = 0.02289088\n",
      "Iteration 262, loss = 0.02283551\n",
      "Iteration 263, loss = 0.02278143\n",
      "Iteration 264, loss = 0.02270912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 265, loss = 0.02262664\n",
      "Iteration 266, loss = 0.02249718\n",
      "Iteration 267, loss = 0.02237529\n",
      "Iteration 268, loss = 0.02232641\n",
      "Iteration 269, loss = 0.02224431\n",
      "Iteration 270, loss = 0.02214494\n",
      "Iteration 271, loss = 0.02206688\n",
      "Iteration 272, loss = 0.02204699\n",
      "Iteration 273, loss = 0.02186943\n",
      "Iteration 274, loss = 0.02181784\n",
      "Iteration 275, loss = 0.02176429\n",
      "Iteration 276, loss = 0.02168752\n",
      "Iteration 277, loss = 0.02161718\n",
      "Iteration 278, loss = 0.02150481\n",
      "Iteration 279, loss = 0.02147178\n",
      "Iteration 280, loss = 0.02136835\n",
      "Iteration 281, loss = 0.02131431\n",
      "Iteration 282, loss = 0.02124676\n",
      "Iteration 283, loss = 0.02117947\n",
      "Iteration 284, loss = 0.02121326\n",
      "Iteration 285, loss = 0.02098908\n",
      "Iteration 286, loss = 0.02093694\n",
      "Iteration 287, loss = 0.02085439\n",
      "Iteration 288, loss = 0.02077838\n",
      "Iteration 289, loss = 0.02069367\n",
      "Iteration 290, loss = 0.02065514\n",
      "Iteration 291, loss = 0.02063742\n",
      "Iteration 292, loss = 0.02046849\n",
      "Iteration 293, loss = 0.02048004\n",
      "Iteration 294, loss = 0.02038452\n",
      "Iteration 295, loss = 0.02021180\n",
      "Iteration 296, loss = 0.02026261\n",
      "Iteration 297, loss = 0.02018076\n",
      "Iteration 298, loss = 0.02018034\n",
      "Iteration 299, loss = 0.02003272\n",
      "Iteration 300, loss = 0.01996926\n",
      "Iteration 301, loss = 0.01988463\n",
      "Iteration 302, loss = 0.01981854\n",
      "Iteration 303, loss = 0.01973936\n",
      "Iteration 304, loss = 0.01967812\n",
      "Iteration 305, loss = 0.01960037\n",
      "Iteration 306, loss = 0.01956354\n",
      "Iteration 307, loss = 0.01947837\n",
      "Iteration 308, loss = 0.01942562\n",
      "Iteration 309, loss = 0.01937810\n",
      "Iteration 310, loss = 0.01934114\n",
      "Iteration 311, loss = 0.01926097\n",
      "Iteration 312, loss = 0.01915505\n",
      "Iteration 313, loss = 0.01911698\n",
      "Iteration 314, loss = 0.01908702\n",
      "Iteration 315, loss = 0.01899417\n",
      "Iteration 316, loss = 0.01894467\n",
      "Iteration 317, loss = 0.01892262\n",
      "Iteration 318, loss = 0.01885271\n",
      "Iteration 319, loss = 0.01871576\n",
      "Iteration 320, loss = 0.01867798\n",
      "Iteration 321, loss = 0.01865418\n",
      "Iteration 322, loss = 0.01858858\n",
      "Iteration 323, loss = 0.01856007\n",
      "Iteration 324, loss = 0.01855450\n",
      "Iteration 325, loss = 0.01856778\n",
      "Iteration 326, loss = 0.01835228\n",
      "Iteration 327, loss = 0.01857386\n",
      "Iteration 328, loss = 0.01837520\n",
      "Iteration 329, loss = 0.01825540\n",
      "Iteration 330, loss = 0.01818584\n",
      "Iteration 331, loss = 0.01810489\n",
      "Iteration 332, loss = 0.01805158\n",
      "Iteration 333, loss = 0.01797560\n",
      "Iteration 334, loss = 0.01793861\n",
      "Iteration 335, loss = 0.01787615\n",
      "Iteration 336, loss = 0.01776398\n",
      "Iteration 337, loss = 0.01771674\n",
      "Iteration 338, loss = 0.01766110\n",
      "Iteration 339, loss = 0.01761047\n",
      "Iteration 340, loss = 0.01763344\n",
      "Iteration 341, loss = 0.01755825\n",
      "Iteration 342, loss = 0.01748233\n",
      "Iteration 343, loss = 0.01739737\n",
      "Iteration 344, loss = 0.01740101\n",
      "Iteration 345, loss = 0.01732468\n",
      "Iteration 346, loss = 0.01729991\n",
      "Iteration 347, loss = 0.01722336\n",
      "Iteration 348, loss = 0.01715826\n",
      "Iteration 349, loss = 0.01712059\n",
      "Iteration 350, loss = 0.01707725\n",
      "Iteration 351, loss = 0.01699802\n",
      "Iteration 352, loss = 0.01704041\n",
      "Iteration 353, loss = 0.01690292\n",
      "Iteration 354, loss = 0.01683610\n",
      "Iteration 355, loss = 0.01687655\n",
      "Iteration 356, loss = 0.01679395\n",
      "Iteration 357, loss = 0.01669135\n",
      "Iteration 358, loss = 0.01666687\n",
      "Iteration 359, loss = 0.01675378\n",
      "Iteration 360, loss = 0.01669831\n",
      "Iteration 361, loss = 0.01652777\n",
      "Iteration 362, loss = 0.01644373\n",
      "Iteration 363, loss = 0.01642476\n",
      "Iteration 364, loss = 0.01653566\n",
      "Iteration 365, loss = 0.01639763\n",
      "Iteration 366, loss = 0.01626232\n",
      "Iteration 367, loss = 0.01630246\n",
      "Iteration 368, loss = 0.01627471\n",
      "Iteration 369, loss = 0.01628072\n",
      "Training loss did not improve more than tol=0.000010 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=100, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=1e-05, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_train, classe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando o modelo criado à partir dos dados de treinamento\n",
    "previsoes = classificador.predict(previsores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a precisão do nosso modelo\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precisao = accuracy_score(classe_test, previsoes)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[435,   1],\n",
       "       [  1,  63]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz = confusion_matrix(classe_test, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultado\n",
    "### Redes Neurais (MLP Classifier - multi layer perceptron)\n",
    "0.996 - max_iter=200, activation='relu', tol=0.0001, solver='adam'    \n",
    "0.996 - max_iter=500, activation='relu', tol=0.00001, solver='adam'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
